<html>

<head>
    <title>Sentence toxicity</title>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            box-sizing: border-box;
            line-height: 1.5;
        }

        h1 {
            margin-bottom: 30px;
            font-size: 34px;
            font-family: 'Roboto Mono', monospace;
        }

        .description {
            margin-bottom: 60px;
        }

        #main {
            width: 1000px;
            margin-top: 50px;
            margin-left: auto;
            margin-right: auto;
        }

        .row {
            display: flex;
            flex-direction: row;
        }

        .row:nth-of-type(2n) {
            background: whitesmoke;
        }

        .row .text {
            flex: 1 1 auto;
        }

        .row .label {
            border-left: solid 1px #ccc;
            width: 60px;
            min-width: 60px;
            max-width: 60px;
        }

        .row:first-of-type .label {
            border: none;
        }

        .row:first-of-type .label,
        .row:first-of-type .text {
            font-weight: bold;
            text-transform: capitalize;
            line-height: 1.4;
            padding-bottom: 20px;
        }

        .positive {
            font-weight: bold;
            text-transform: capitalize;
            color: red;
        }

        .text,
        .label {
            padding: 10px;
            text-transform: capitalize;
        }

        #classify-new-text-input {
            border: none;
            border-bottom: solid 1px #ccc;
            font-size: 14px;
            line-height: 2;
            width: calc(100% - 127px);
            margin-right: 15px;
            padding-left: 5px;
            padding-right: 5px;
            padding-top: 4px;
            padding-bottom: 4px;
        }

        #classify-new-text,
        #classify-new-text-input {
            display: inline-block;
            vertical-align: top;
        }

        #classify-new-text {
            cursor: pointer;
            text-transform: uppercase;
            padding: 9px 14px 9px 14px;
            font-size: 13px;
            border-radius: 3px;
            letter-spacing: 1px;
            background: #0277bd;
            color: white;
        }

        #table-wrapper {
            margin-bottom: 60px;
        }

        p {
            font-weight: bold;
        }
    </style>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <link href="https://fonts.googleapis.com/css?family=Roboto|Roboto+Mono&display=swap" rel="stylesheet">
    <script src="js/tfjs.js"></script>
    <script src="js/toxicity.js"></script>

</head>
<!-- This is a demo of the TensorFlow.js toxicity model, which classifies text according to
            whether it exhibits offensive attributes (i.e. profanity, sexual explicitness). The samples in the table
            below were taken from this -->

<body>
    <div id='main'>
        <h1>Sentence toxicity</h1>
        <div class="description">Check toxicity of any statement on the grounds of it exhibiting offensive attributes
            (i.e. profanity, sexual explicitness).

        </div>

        <div id="table-wrapper"></div>

        <p>Enter statement below to check for it's toxicity.</p>
        <div>
            <input id="classify-new-text-input" placeholder="i.e. 'you suck'">
            <div id="classify-new-text">Check</div>
        </div>
    </div>

</body>
<script src="index.js"></script>

</html>